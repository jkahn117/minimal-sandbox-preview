# Decisions and Changes Log

Decisions made and problems solved while getting the Cloudflare Sandbox SDK
running with Astro on Cloudflare Workers. Listed roughly in the order we
encountered them.

---

## 1. Astro v5 -> v6 beta upgrade

**Problem:** Astro v5 with `@astrojs/cloudflare` v12 runs its dev server on
Node.js, not workerd. This means `cloudflare:workers` imports, Durable Object
bindings, and `@cloudflare/sandbox` all fail to resolve in local dev.

**Decision:** Upgrade to Astro v6 beta (`astro@6.0.0-beta.13`) with
`@astrojs/cloudflare@13.0.0-beta.8`. The v6 dev server runs on workerd,
so Cloudflare-specific APIs work identically in dev and production.

**Trade-off:** Beta software. The API surface may still change before GA.

---

## 2. Dropped `workerEntryPoint` adapter config

**Problem:** Astro v6 removed the `workerEntryPoint` option from the
Cloudflare adapter.

**Decision:** Set `"main": "./src/worker-entry.ts"` in `wrangler.jsonc`
instead. The custom entry imports the Astro handler from
`@astrojs/cloudflare/entrypoints/server` and re-exports the `Sandbox`
Durable Object class:

```typescript
import handler from "@astrojs/cloudflare/entrypoints/server";
import { Sandbox } from "@cloudflare/sandbox";

export { Sandbox };

export default {
  async fetch(request, env, ctx) {
    return handler.fetch(request, env, ctx);
  },
} satisfies ExportedHandler<Env>;
```

---

## 3. Dropped Hono — not needed

**Problem:** The original plan used Hono for routing (`proxyToSandbox`
middleware, API endpoints, WebSocket handler). But with Astro handling
all routing, Hono added an unnecessary layer.

**Decision:** Removed Hono entirely. Astro middleware, actions, and API
routes replace all Hono functionality:

| Hono role              | Replaced by                      |
|------------------------|----------------------------------|
| `proxyToSandbox` mw    | `src/middleware.ts`              |
| `POST /api/start`      | `src/actions/index.ts`           |
| `GET /ws`              | `src/pages/api/ws.ts`            |
| HTML response          | `src/pages/index.astro`          |

---

## 4. `cloudflare:workers` for env bindings

**Problem:** Astro v6 removed `Astro.locals.runtime.env`. Need a way to
access `Env` bindings (Durable Object namespaces, service bindings).

**Decision:** Use `import { env } from "cloudflare:workers"` and cast with
the `Env` type from `worker-configuration.d.ts` (auto-generated by
`wrangler types`):

```typescript
import { env } from "cloudflare:workers";
const { Sandbox } = env as Env;
```

This is the pattern documented in the Astro v6 Cloudflare blog post.
`cloudflare:workers` provides the runtime values; `Env` provides the types.

---

## 5. `waitUntil` required for background init

**Problem:** The sandbox initialization takes 30-40 seconds (mkdir, writeFile,
npm install, startProcess, health check, exposePort). workerd kills any async
work that outlives the response — a fire-and-forget `initializeSandbox()`
promise gets terminated.

**Decision:** Use `context.locals.cfContext.waitUntil()` from the Astro action
handler to keep the isolate alive:

```typescript
const { cfContext } = context.locals;
const initPromise = initializeSandbox(host, sandboxBinding);
cfContext.waitUntil(initPromise);
```

---

## 6. Dynamic import for `@cloudflare/sandbox`

**Problem:** Top-level `import { getSandbox } from "@cloudflare/sandbox"`
in Astro actions and API routes causes module resolution failures, even with
Astro v6's workerd dev server.

**Decision:** Use dynamic import inside the handler function:

```typescript
const { getSandbox } = await import("@cloudflare/sandbox");
```

This also applies to `proxyToSandbox` in the middleware.

---

## 7. Astro Actions instead of API routes for RPC

**Problem:** The original plan had `POST /api/start` as a plain API route.
Astro Actions provide type-safe RPC with automatic serialization.

**Decision:** Replaced the API route with an Astro action
(`actions.startSandbox()`). The action is called from the client-side
component script with full type safety:

```typescript
const result = await actions.startSandbox({
  host: window.location.host,
});
```

The `/api/start` route was deleted.

---

## 8. WebSocket kept as API route (actions can't do WebSockets)

**Problem:** Astro Actions return JSON responses — they can't handle
WebSocket upgrades.

**Decision:** Keep `/api/ws` as a standard Astro API route. The action and
WebSocket route share module-level state via `src/lib/sandbox.ts` (the
`connections` Set, `isInitialized`, `previewUrl`, etc.).

---

## 9. Polling as deferred fallback to WebSocket (revised in decision 19)

**Problem:** The `waitUntil` promise runs initialization outside the
original request's I/O context. WebSocket broadcasts from `waitUntil` may
not reliably deliver to clients connected in a different request.

Symptom: The client WebSocket would show "Installing dependencies..." and
then never progress to "ready", even though server logs showed successful
initialization.

**Original decision:** Polling ran immediately alongside WebSocket every
3 seconds. This caused duplicate paired POST requests to
`/_actions/startSandbox/` (the initial action call + first poll tick fired
nearly simultaneously), flooding the server with unnecessary requests and
compounding a container `max_instances` exhaustion problem.

**Revised decision (see decision 19):** Polling is now a deferred
last-resort fallback. WebSocket is the primary progress channel; polling
only activates if WebSocket is silent after 10 seconds.

---

## 10. `proxyToSandbox` in Astro middleware

**Problem:** Sandbox preview URLs use subdomain-based routing (e.g.
`http://3001-sandbox-id-token.localhost:4321/`). Without `proxyToSandbox()`,
these requests hit Astro's router and get routed as normal pages — returning
the index page HTML instead of the Express server's JSON response.

The Sandbox SDK docs say `proxyToSandbox()` must be called first in the
Worker's fetch handler.

**Decision:** Created `src/middleware.ts` using `defineMiddleware`. Astro
middleware runs before all pages, actions, and API routes — the earliest
interception point within the Astro framework:

```typescript
export const onRequest = defineMiddleware(async ({ request }, next) => {
  const { Sandbox } = env as Env;
  if (Sandbox) {
    const { proxyToSandbox } = await import("@cloudflare/sandbox");
    const proxyResponse = await proxyToSandbox(request, env as any);
    if (proxyResponse) return proxyResponse;
  }
  return next();
});
```

We initially put this in `worker-entry.ts` (before the Astro handler), which
also works, but middleware is the Astro-idiomatic place — it stays within the
framework's request pipeline and has access to Astro's context if needed.

---

## 11. Containers config must be at top level

**Problem:** During development, putting the `containers` array only in
`env.production` in `wrangler.jsonc` caused the Durable Object to fail with
"Containers have not been enabled for this Durable Object class". Moving it
to top level initially caused a "Build ID should be set if containers are
defined" error with older Astro/wrangler versions.

**Decision:** With Astro v6 beta + wrangler 4.66+, containers at top level
works correctly. The container image is built via Docker on `astro dev` startup
and the DO has access to the container binding.

---

## 12. Double-initialization guard

**Problem:** The first page load triggers the Astro action from the
client-side script. If the browser makes multiple requests (or the page
reloads during Vite HMR), `initializeSandbox()` could run concurrently,
causing `PortAlreadyExposedError`.

**Decision:** Added an `isInitializing` boolean guard in `src/lib/sandbox.ts`.
The `startSandbox()` function checks three states:

1. `isInitialized` — already done, return preview URL
2. `isInitializing` — in progress, return "already in progress"
3. Neither — start initialization, set `isInitializing = true`

---

## 13. `npm install` reports "Success: false" but works

**Observation:** `sandbox.exec("npm install")` logs
`"npm install, Success: false"` but the Express server starts and runs fine
afterward. The container's Dockerfile pre-installs dependencies via
`RUN pnpm install`, so `npm install` at runtime likely finds everything
already present and exits with a non-zero code (possibly due to lockfile
format mismatch between pnpm and npm).

**Decision:** Not blocking. The pre-installed dependencies from the Docker
build are sufficient. A future improvement could skip the runtime
`npm install` entirely or switch to `pnpm install`.

---

## 14. Port 3000 is reserved

**Discovery:** The Sandbox SDK reserves port 3000 for its internal Bun
server. Using it for the Express app causes conflicts.

**Decision:** Use port 3001 for the Express server.

---

## 15. `normalizeId: true` for preview URLs

**Problem:** Preview URLs extract the sandbox ID from the hostname, which is
always lowercased (per RFC 3986). If the Durable Object ID has uppercase
characters, the preview URL routes to a different (non-existent) DO.

**Decision:** Always pass `normalizeId: true` to `getSandbox()`:

```typescript
const sandbox = getSandbox(env.Sandbox, "minimal-example-sandbox", {
  normalizeId: true,
});
```

---

## 16. Post-build patch for deploy routes

**Problem:** `astro build` generates `dist/server/wrangler.json` which
wrangler uses for deploy (via `.wrangler/deploy/config.json` redirect). The
Astro Cloudflare adapter copies most fields from `wrangler.jsonc` into this
generated config — bindings, containers, migrations, etc. — but it **drops
`routes` and `workers_dev`**. Without these, `wrangler deploy` uploads the
worker but doesn't attach it to the custom domain (`sandbox.cfsa.dev` /
`*.sandbox.cfsa.dev`), so the worker is unreachable.

**Discovery:** Running `wrangler deploy --dry-run` showed the worker
deploying with all bindings correct but no routes listed. Inspecting
`dist/server/wrangler.json` confirmed `routes` was absent and `triggers`
was empty `{}`.

**Decision:** Added `scripts/patch-deploy-config.mjs` — a small Node script
that runs between `astro build` and `wrangler deploy`. It reads the generated
`dist/server/wrangler.json`, injects the `routes` array and
`workers_dev: false`, and writes it back:

```javascript
const generatedPath = resolve("dist/server/wrangler.json");
const generated = JSON.parse(readFileSync(generatedPath, "utf-8"));

generated.routes = [
  { pattern: "sandbox.cfsa.dev", custom_domain: true },
  { pattern: "*.sandbox.cfsa.dev", zone_name: "cfsa.dev" },
];
generated.workers_dev = false;

writeFileSync(generatedPath, JSON.stringify(generated, null, 2));
```

The deploy script in `package.json` chains accordingly:

```
"deploy": "wrangler types && astro build && node scripts/patch-deploy-config.mjs && wrangler deploy"
```

**Trade-off:** Fragile — if the adapter changes its generated config format
or routes start being carried through, this script would need updating or
removal. Should be revisited when Astro v6 reaches GA.

---

## 17. `[object Object]` response — workerd AsyncIterable bug

**Problem:** After deploying, every page returned `[object Object]`
(15 bytes, `content-type: text/html`). The worker was invoked, the
middleware ran, `app.render()` returned a valid `Response` — but the
body was wrong.

**Root cause:** A known Astro + Cloudflare adapter bug
(https://github.com/withastro/astro/issues/14511). With
`nodejs_compat` enabled, workerd exposes native `process` v2, which
makes Astro's Node.js detection (`isNode`) evaluate to `true`. Astro
then returns AsyncIterable response bodies instead of ReadableStreams.
workerd's `Response` constructor doesn't support AsyncIterable, so the
body gets coerced to `"[object Object]"`.

The issue affects:
- wrangler >= 4.40.3 with `nodejs_compat`
- compatibility_date < `2026-02-19` (when `fetch_iterable_type_support`
  auto-enables)

**Decision:** Added `fetch_iterable_type_support` to compatibility flags,
which makes workerd's Response constructor handle AsyncIterable bodies:

```jsonc
"compatibility_flags": ["nodejs_compat", "fetch_iterable_type_support"]
```

This flag auto-enables at compat date `2026-02-19` — one day after our
`2026-02-18` date. An alternative workaround is
`disable_nodejs_process_v2`, which prevents Astro from detecting Node.js
in the first place.

**Also applied:** Hardened the middleware `proxyToSandbox` check from
`if (proxyResponse)` to `if (proxyResponse instanceof Response)` and
added try/catch — a defensive improvement discovered during debugging,
kept even though it wasn't the root cause.

---

## 18. Removed redundant runtime `npm install`

**Problem:** `sandbox.exec("npm install", { cwd: "/workspace" })` was run
during sandbox initialization, but the Dockerfile already pre-installs
Express via `pnpm install`. The runtime npm install added ~10 seconds to
init time and always reported "Success: false" (likely a lockfile format
mismatch between npm and pnpm).

**Decision:** Removed the `npm install` step from `src/lib/sandbox.ts`.
The container starts with deps already installed via the Docker build.
This cuts initialization time by ~10 seconds.

---

## 19. Polling demoted to deferred WebSocket fallback

**Problem:** The original polling implementation (decision 9) called
`actions.startSandbox()` every 3 seconds immediately alongside the
WebSocket connection. This caused two issues:

1. **Duplicate requests** — The initial `await actions.startSandbox()`
   takes ~3s to return. By the time it returns "initializing" and
   `startPolling()` fires, the first `setInterval` tick is nearly
   simultaneous, producing paired POST requests visible in logs
   (`:16/:16`, `:19/:19`, etc.). If a poll request takes longer than the
   interval, ticks stack up.
2. **Compounded container exhaustion** — Each redundant POST hits the
   server-side `startSandbox()`, which is guarded by `isInitializing` so
   it doesn't re-init, but the traffic is wasteful and makes log analysis
   harder when debugging the `max_instances` error.

**Decision:** Restructured polling as a true last-resort fallback:

- **WebSocket is primary.** All real-time progress comes via WS. A
  `wsHasDelivered` flag tracks whether WS has delivered a *substantive*
  message (progress/ready/error).
- **5-second grace period.** After the initial action call returns
  "initializing", a `setTimeout(5s)` is scheduled. Only if WebSocket has
  not delivered any substantive message after 5 seconds does polling
  activate. (Originally 10s, reduced because init can complete in ~5s.)
- **Self-canceling.** If WebSocket comes alive while polling is running,
  the next poll tick sees `wsHasDelivered === true` and clears the
  interval.
- **5-second interval** (was 3s) — less aggressive since this is purely
  a backup.
- **Guard against duplicates** — `startPolling()` returns early if a
  timer is already active.
- **Only substantive WS messages count.** The WS route used to send a
  `{ type: "connected" }` handshake ack when no init state existed yet.
  This set `wsHasDelivered = true`, which suppressed polling permanently
  — even though WS hadn't actually delivered any progress info. Broadcasts
  from `waitUntil` often don't arrive, so polling never activated and the
  client was stuck on "Initializing..." forever. Fixed by: (a) removing
  the `"connected"` message from the WS route, and (b) only setting
  `wsHasDelivered` on `progress`, `ready`, or `error` messages.

Flow:
```
init() → action call → connect WS → schedule fallback timer (5s)
  ├─ WS delivers progress/ready/error → wsHasDelivered=true → polling skipped
  └─ WS silent after 5s → startPolling(5s) → self-cancels if WS wakes
```

**Trade-off:** 5s delay before polling starts if WS is completely dead.
Acceptable — the loading spinner is visible throughout.

---

## 20. Container TTL cleanup + increased max_instances

**Problem:** Each page view creates a unique sandbox ID
(`sandbox-${crypto.randomUUID()}`), which maps to a unique Durable Object
and container. With `max_instances: 1`, a single stale container from a
previous page view blocked all new containers. Even with higher limits,
containers from abandoned page views would accumulate indefinitely since
nothing destroyed them — the in-memory `Map<sandboxId, SandboxState>`
grew unboundedly and containers sat idle consuming instance slots.

**Root cause in logs:** `"Maximum number of running container instances
exceeded. Try again later, or try configuring a higher value for
max_instances"` — the single allowed instance was occupied by a container
from a previous deploy/test.

**Decision:** Two-layer defense:

1. **Increased `max_instances` from 1 to 5** in `wrangler.jsonc`. Allows
   reasonable concurrency for a prototype (5 concurrent sandbox
   containers).

2. **TTL-based cleanup** in `src/lib/sandbox.ts`:
   - Each `SandboxState` tracks `lastActivity` timestamp and holds a
     `destroyTimer` (setTimeout handle).
   - `touchSandbox()` resets the TTL on every status check (action poll
     or ready-state return), keeping active sandboxes alive.
   - `scheduleDestroy()` sets a 5-minute timer. When it fires,
     `destroySandbox()` calls `sandbox.destroy()` (kills container,
     frees processes, ports, files) and removes the entry from the
     in-memory Map.
   - `sleepAfter: "5m"` is also passed to `getSandbox()` as a safety
     net, aligned with the JS-level TTL — the container auto-sleeps
     after 5 minutes of inactivity even if the Worker isolate is evicted
     before the JS timer fires. Originally set to 3m, but that was too
     aggressive — the container would sleep before the user had time to
     see the iframe (especially with DNS propagation delays).

Lifecycle:
```
Page load → init → container starts → ready
  ↓
touchSandbox() → scheduleDestroy(5min)
  ↓
Each poll/status check → touchSandbox() → timer reset
  ↓
User leaves (no more polls) → 5min passes → destroySandbox()
  → sandbox.destroy() → container killed → Map entry deleted
  ↓
Safety net: container also auto-sleeps after 5min inactivity
```

**Caveat:** The `setTimeout` lives in the Worker isolate. If the isolate
is evicted (e.g. after 30s of no requests), the timer is lost. The
`sleepAfter: "5m"` on the container itself provides a belt-and-suspenders
fallback — the container will still stop on its own. A more robust
solution would use DO alarms, but that requires a custom DO class (the
Sandbox SDK provides its own DO).

---

## 21. WS "connected" ack suppressed polling — iframe never loaded

**Problem:** After deploying, the sandbox initialized successfully
(logs showed "Initialized successfully, preview: ..."), the preview URL
worked when accessed directly in the browser, but the iframe in the page
never loaded. The client was stuck on "Initializing..." forever.

**Root cause:** A race condition between the WebSocket handshake and the
polling fallback:

1. Client calls `actions.startSandbox()` → returns "initializing"
2. Client connects WS → WS route sends `{ type: "connected" }` (no
   init state available yet)
3. Client receives "connected" → sets `wsHasDelivered = true`
4. Init completes in ~5s, `broadcast()` sends `{ type: "ready" }` from
   inside `waitUntil` — but this broadcast often doesn't arrive (known
   cross-I/O-context issue, see decision 9)
5. Poll fallback timer fires after 5s → checks `wsHasDelivered` → it's
   `true` (from the "connected" ack) → **polling never starts**
6. Client is stuck forever — WS won't deliver "ready", polling won't
   run

**Decision:** Two fixes:

1. **Removed `"connected"` ack from WS route** (`src/pages/api/ws.ts`).
   If no init state exists, the WS stays silent. The client already
   shows "Initializing..." from the action response, so the ack served
   no purpose.

2. **Only substantive messages set `wsHasDelivered`** in the component.
   Only `progress`, `ready`, and `error` messages count. Any other
   message type (including stale "connected" if it were to come back)
   is ignored for the purposes of suppressing the poll fallback.

Also reduced `POLL_FALLBACK_DELAY` from 10s to 5s. Since init now
completes in ~5s (health check passes on first attempt), the first poll
fires shortly after init is likely done, minimizing the gap between
completion and iframe load.

---

## 22. Recover from isolate eviction — check container before re-init

**Problem:** After the first init succeeded, the Worker isolate was
evicted (deploy, inactivity, or code update). The new isolate started
with an empty `sandboxes` Map — no knowledge that the container was
already running with port 3001 exposed. When the client's poll hit this
fresh isolate, `startSandbox()` saw no state and kicked off
`initializeSandbox()` from scratch. This hit `PortAlreadyExposedError`
because port 3001 was already exposed from the first init. The error
triggered the error-reset logic, which cleared the error and retried on
the next poll — creating an infinite loop of:

```
poll → no state → init → PortAlreadyExposedError → error stored
  → next poll → error detected → reset error → init → PortAlreadyExposed...
```

Meanwhile the container was performing redundant mkdir/writeFile/
startProcess operations every 5 seconds.

**Decision:** Three fixes:

1. **Recovery check via `getExposedPorts()`** — At the top of
   `initializeSandbox()`, before any mkdir/writeFile, call
   `sandbox.getExposedPorts()`. If port 3001 is already exposed, skip
   all init steps and go straight to "ready" by calling `markReady()`.
   This handles the isolate-eviction case gracefully.

2. **Catch `PortAlreadyExposedError` at `exposePort()`** — Even with
   the recovery check, a race condition is possible (concurrent request
   exposes the port between our check and the `exposePort` call). The
   catch block constructs the preview URL from the known pattern and
   treats it as success.

3. **Stop auto-retrying on error** — The `startSandbox()` function no
   longer resets `initError` and retries. If init failed, it returns
   `{ status: "error" }` to the client. The user can retry via the
   Retry button (which reloads the page with a fresh sandboxId). This
   breaks the infinite retry loop that was hammering the container.

Also extracted `markReady()` helper to deduplicate the state-transition
logic between the happy path, the recovery check, and the
PortAlreadyExposedError catch.

---

## Summary of final architecture vs original plan

| Aspect                | Original plan                   | Final implementation                         |
|-----------------------|---------------------------------|----------------------------------------------|
| **Astro version**     | v5 + adapter v12                | v6 beta (`6.0.0-beta.13`) + adapter v13 beta |
| **Dev runtime**       | Node.js (needed polyfills)      | workerd (same as production)                 |
| **Router**            | Hono                            | Astro (middleware + actions + API routes)     |
| **Env access**        | `locals.runtime.env`            | `import { env } from "cloudflare:workers"`   |
| **Init trigger**      | `POST /api/start`               | `actions.startSandbox({ sandboxId, host })`  |
| **Preview proxy**     | Hono middleware                 | Astro middleware (`proxyToSandbox`)           |
| **Worker entry**      | `src/worker/index.ts` (Hono)    | `src/worker-entry.ts` (thin shim)            |
| **Progress**          | WebSocket only                  | WebSocket primary + deferred polling fallback|
| **Sandbox scope**     | Single shared sandbox           | Per-page-view unique `sandboxId`             |
| **Container cleanup** | Not addressed                   | JS TTL (5min) + `sleepAfter:"5m"` safety net |
| **Deploy config**     | Standard wrangler deploy        | Post-build patch script for routes           |
| **Response body bug** | Not encountered (v5)            | `fetch_iterable_type_support` workaround     |
| **Isolate eviction**  | Not addressed                   | `getExposedPorts()` recovery check           |
| **Error handling**    | Not addressed                   | No auto-retry; user retries via page reload  |

## Quick reference: key technical details

| Detail                     | Value / pattern                                      |
|----------------------------|------------------------------------------------------|
| **Container port**         | 3001 (port 3000 reserved by Sandbox SDK)             |
| **Container image**        | `docker.io/cloudflare/sandbox:0.7.4`                 |
| **SDK package**            | `@cloudflare/sandbox@0.7.4`                          |
| **max_instances**          | 5                                                    |
| **sleepAfter**             | `"5m"`                                               |
| **JS TTL**                 | 5 minutes (`SANDBOX_TTL_MS`)                         |
| **Polling fallback delay** | 5 seconds (`POLL_FALLBACK_DELAY`)                    |
| **Polling interval**       | 5 seconds (`POLL_INTERVAL`)                          |
| **Health check**           | 10 attempts, 2s apart, `curl localhost:3001/health`  |
| **Compat date**            | `2026-02-19` (auto-enables `fetch_iterable_type_support`) |
| **Compat flags**           | `nodejs_compat`                                      |
| **normalizeId**            | `true` (required for preview URLs)                   |
| **Custom domain**          | `sandbox.cfsa.dev` + `*.sandbox.cfsa.dev`            |
| **Deploy pipeline**        | `wrangler types → astro build → patch script → wrangler deploy` |
